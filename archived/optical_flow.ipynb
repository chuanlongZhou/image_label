{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the directory containing your images\n",
    "image_folder = 'ChandrapurDaily'\n",
    "video_name = 'output.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "images.sort()  # Sort the images if needed\n",
    "\n",
    "# Read the first image to determine the frame size\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter(video_name, fourcc, 3, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = 'ChandrapurDaily'\n",
    "\n",
    "for img in os.listdir(folder):\n",
    "    if img!=\"Chandrapur_20230319.png\":\n",
    "        continue\n",
    "    image = cv2.imread(os.path.join(folder, img))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # normalize the image\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Apply thresholding to isolate clouds\n",
    "    # Adjust the threshold value as needed\n",
    "    _, thresholded = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Optional: Filter contours by size\n",
    "    min_area = 500  # minimum area of the cloud\n",
    "    cloud_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "    # Create a mask for the clouds\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, cloud_contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Extract clouds from the original image (optional)\n",
    "    clouds = cv2.bitwise_and(image, image, mask=mask)\n",
    "    combined_frame = cv2.hconcat([cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), clouds])\n",
    "    # Save or display the results\n",
    "    # cv2.imwrite('clouds_extracted.jpg', combined_frame)\n",
    "    cv2.imshow('Clouds', combined_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the two images\n",
    "image1 = cv2.imread('ChandrapurDaily\\Chandrapur_20230423.png')\n",
    "image2 = cv2.imread('ChandrapurDaily\\Chandrapur_20230319.png')\n",
    "# image1 = cv2.convertScaleAbs(image1, alpha=2, beta=30)\n",
    "# image2 = cv2.convertScaleAbs(image2, alpha=1.2, beta=0)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# # add guassian blur \n",
    "# kernel_size = (5, 5)\n",
    "# gray1 = cv2.GaussianBlur(gray1, kernel_size, cv2.BORDER_DEFAULT)\n",
    "# gray2 = cv2.GaussianBlur(gray2, kernel_size, cv2.BORDER_DEFAULT)\n",
    "# normalize with min max\n",
    "gray1 = cv2.normalize(gray1, None, 0, 255, cv2.NORM_MINMAX)\n",
    "gray2 = cv2.normalize(gray2, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "hsv = np.zeros_like(image1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "# Initialize points to track\n",
    "n_step = 5  # Number of points to track\n",
    "points_to_track = np.array([[[x, y]] for y in range(0, gray1.shape[0], n_step)\n",
    "                                         for x in range(0, gray1.shape[1], n_step)], dtype=np.float32)\n",
    "\n",
    "# Lucas-Kanade parameters\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Calculate optical flow\n",
    "points2, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, points_to_track, None, **lk_params)\n",
    "flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Convert to magnitude and angle\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "mag[mag < np.quantile(mag, 0.50)] = 0\n",
    "\n",
    "# Set image hue according to the angle of optical flow\n",
    "hsv[..., 0] = ang * (180 / np.pi / 2)\n",
    "# hsv[..., 0] = 255\n",
    "# Set image value according to the normalized magnitude of optical flow\n",
    "hsv[..., 0] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "hsv[..., 1] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "# Convert HSV to RGB\n",
    "rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "# cv2.imshow(\"Optical Flow_1\", hsv)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Select good points\n",
    "good_new = points2[st == 1]\n",
    "good_old = points_to_track[st == 1]\n",
    "\n",
    "# Draw tracks\n",
    "output_image = cv2.cvtColor(gray1, cv2.COLOR_GRAY2BGR)\n",
    "for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "    a, b = new.ravel()\n",
    "    c, d = old.ravel()\n",
    "    a, b, c, d = int(a), int(b), int(c), int(d)  # Convert to integers\n",
    "    cv2.line(output_image, (a, b), (c, d), (0, 255, 0), 1)\n",
    "    cv2.circle(output_image, (a, b), 1, (0, 0, 255), -1)\n",
    "\n",
    "combined_frame = cv2.vconcat([\n",
    "                            # cv2.hconcat([image1, image2]),\n",
    "                            cv2.hconcat([cv2.cvtColor(gray1, cv2.COLOR_GRAY2BGR), cv2.cvtColor(gray2, cv2.COLOR_GRAY2BGR)]),    \n",
    "                            cv2.hconcat([hsv, output_image])])\n",
    "\n",
    "cv2.imshow('Optical Flow', combined_frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034024477005005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(ang, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 369)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Optical Flow\", cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ChandrapurDaily'\n",
    "# Read the two images\n",
    "base = cv2.imread('ChandrapurDaily\\Chandrapur_20230423.png')\n",
    "hsv = np.zeros_like(base)\n",
    "hsv[...,1] = 255\n",
    "# Convert to grayscale\n",
    "base_grey = cv2.cvtColor(base, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "height, width, layers = 369, 369, 3\n",
    "video_name = \"flow2.avi\"\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter(video_name, fourcc, 3, (width, height))\n",
    "\n",
    "\n",
    "folder = 'ChandrapurDaily'\n",
    "\n",
    "for image in os.listdir(folder):\n",
    "    image2 = cv2.imread(os.path.join(folder, image))\n",
    "    # Convert to grayscale\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(base_grey, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Convert to magnitude and angle\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Set image hue according to the angle of optical flow\n",
    "    hsv[..., 0] = ang * (180 / np.pi / 2)\n",
    "    # Set image value according to the normalized magnitude of optical flow\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Convert HSV to RGB\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    # Display image\n",
    "    cv2.imshow(\"Optical Flow\", rgb)\n",
    "    # cv2.waitKey(0)\n",
    "    # Save image\n",
    "    cv2.imwrite(\"optical_flow.png\", rgb)\n",
    "    video.write(rgb)    \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"output.avi\")\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "\n",
    "height, width, layers = 369, 369, 3\n",
    "video_name = \"flow.avi\"\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter(video_name, fourcc, 3, (width, height))\n",
    "\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    # Check if frame is read correctly\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('frame2',rgb)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('opticalfb.png',frame2)\n",
    "        cv2.imwrite('opticalhsv.png',rgb)\n",
    "    video.write(rgb)    \n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m p1, st, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(old_gray, frame_gray, p0, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlk_params)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Select good points\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m good_new \u001b[38;5;241m=\u001b[39m \u001b[43mp1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mst\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     38\u001b[0m good_old \u001b[38;5;241m=\u001b[39m p0[st\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# draw the tracks\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# not wortking\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    # Check if frame is read correctly\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        a, b, c, d = int(a), int(b), int(c), int(d)  # Convert to integers\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the two videos\n",
    "cap1 = cv2.VideoCapture('output.avi')\n",
    "cap2 = cv2.VideoCapture('flow2.avi')\n",
    "\n",
    "# Check if videos opened successfully\n",
    "if not cap1.isOpened() or not cap2.isOpened():\n",
    "    print(\"Error opening video files\")\n",
    "    exit()\n",
    "\n",
    "# Get properties from the videos\n",
    "width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Determine the combined width and the height (maximum height of the two videos)\n",
    "combined_width = width1 + width2\n",
    "combined_height = max(height1, height2)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('combined_output.avi', fourcc, 2.0, (combined_width, combined_height))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    # Check if both frames are read correctly\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    # Resize frames to have the same height\n",
    "    if height1 != combined_height:\n",
    "        frame1 = cv2.resize(frame1, (int(frame1.shape[1] * combined_height / frame1.shape[0]), combined_height))\n",
    "    if height2 != combined_height:\n",
    "        frame2 = cv2.resize(frame2, (int(frame2.shape[1] * combined_height / frame2.shape[0]), combined_height))\n",
    "\n",
    "    # Concatenate frames horizontally\n",
    "    combined_frame = cv2.hconcat([frame1, frame2])\n",
    "    cv2.imshow('frame2',combined_frame)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "\n",
    "    # Write the combined frame\n",
    "    out.write(combined_frame)\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
